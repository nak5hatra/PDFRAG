# ğŸ§  RAG Q&A Conversation With PDF (Chat History Enabled)

This project is a **Conversational Retrieval-Augmented Generation (RAG)** app built using **Streamlit**. It allows users to **upload PDF documents** and interact with them in a **chat-like interface**, powered by **LangChain**, **Groq**, and **Chroma**. The system maintains **chat history**, supports **context-aware question reformulation**, and uses **HuggingFace embeddings** for document retrieval.

---

## ğŸš€ Features

- ğŸ“„ Upload one or more PDF documents.
- ğŸ—£ï¸ Ask questions about the content in natural language.
- ğŸ’¬ Maintains full chat history for context-aware responses.
- ğŸ” Reformulates user questions based on conversation history.
- ğŸ§  Uses RAG (Retrieval-Augmented Generation) to answer from relevant document chunks.
- âš¡ Powered by Groqâ€™s **Gemma2-9b-It** language model.
- ğŸ§© Modular and extendable with LangChain components.

---

## ğŸ§° Built With

- [Streamlit](https://streamlit.io/)
- [LangChain](https://www.langchain.com/)
- [LangChain Chroma](https://python.langchain.com/docs/integrations/vectorstores/chroma)
- [Groq API](https://console.groq.com/)
- [HuggingFace Transformers](https://huggingface.co/)
- [Chroma Vectorstore](https://www.trychroma.com/)
- [Python-dotenv](https://pypi.org/project/python-dotenv/)

---

## ğŸ“¦ Installation

1. **Clone the repository**:

   ```bash
   git clone https://github.com/nak5hatra/PDFRAG.git
   cd PDFRAG
   ```

2. **Create a virtual environment**:
    ```bash
    python -m venv venv
    source venv/bin/activate  # or venv\Scripts\activate on Windows
    ```
3. **Install dependencies**:
    ```bbash
    pip install -r requirements.txt
    ```
4. **Set up environment variables**:
    Create a .env file and add your HuggingFace token:
    ```bash
    HF_TOKEN=your_huggingface_token
    ```
## ğŸ”‘ Required API Keys

- Groq API Key (for LLM processing)
- HuggingFace Token (for generating document embeddings)

## â–¶ï¸ Running the App
    streamlit run app.py
### Once running, you'll be able to:
  1. Enter your Groq API key in the UI.
  2. Upload one or more PDF files.
  3. Start chatting and asking questions about the PDF content!

## ğŸ“‚ Project Structure
    â”œâ”€â”€ app.py              # Main Streamlit app
    â”œâ”€â”€ requirements.txt    # Python dependencies
    â””â”€â”€ .env                # Environment variables (not included in repo)
## ğŸ“Œ Notes
- Chunk size and overlap are set to 5000 and 500 respectively for optimal PDF splitting.
- Chat history is stored in-memory per session using Streamlitâ€™s session state.
- Reformulated queries help handle follow-up questions more intelligently.

## ğŸ’¡ Acknowledgments
Thanks to the teams behind:
  - LangChain
  - Groq
  - HuggingFace
  - Streamlit
  - Chroma
